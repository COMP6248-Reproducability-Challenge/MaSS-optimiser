{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport torchvision\nimport pandas as pd\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport ssl\nimport seaborn as sns\nimport time\n\nsns.set_theme()\nssl._create_default_https_context = ssl._create_unverified_context","metadata":{"id":"tBEjqnXnGIzn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"id":"ryBw13Y_GQOw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hyper-parameters\nnum_epochs = 300\nbatch_size = 64\nlearning_rate = 0.1","metadata":{"id":"Q37yHSzZGRua"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dataset has PILImage images of range [0, 1].\n# We transform them to Tensors of normalized range [-1, 1]\ntransform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n     transforms.RandomHorizontalFlip(),\n     transforms.RandomAffine(0, translate=(0.1, 0.1))])\n\n# CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class\ntrain_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                        download=True, transform=transform)\n\ntest_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n                                       download=True, transform=transform)\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n                                          shuffle=True)\n\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n                                         shuffle=False)\n\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')","metadata":{"id":"dLfUS6y0GVA2","outputId":"54048c4b-349d-4c47-afbd-b3940b8c92ca"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.optim import Optimizer\n\n\n\nclass MaSS(Optimizer):\n    def __init__(self, params, lr=0, alpha=0, kappa_t=0):\n        if lr and lr < 0.0:\n            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n        if alpha < 0.0:\n            raise ValueError(\"Invalid alpha value: {}\".format(alpha))\n        if kappa_t < 0.0:\n            raise ValueError(\"Invalid kappa_t value: {}\".format(kappa_t))\n\n        defaults = dict(lr=lr, alpha=alpha, kappa_t=kappa_t)\n\n        super(MaSS, self).__init__(params, defaults)\n\n    @torch.no_grad()\n    def step(self, closure=None):\n        \"\"\"Performs a single optimization step.\n        Args:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"\n        loss = None\n        if closure is not None:\n            with torch.enable_grad():\n                loss = closure()\n\n        for group in self.param_groups:\n            params_with_grad = []\n            w_list = []\n            d_p_list = []\n            lr = group['lr']\n            alpha = group['alpha']\n            kappa_t = group['kappa_t']\n            delta = lr / alpha / kappa_t\n            gamma = (1 - alpha)/(1 + alpha)\n            lr2 = (lr - alpha * delta)/(1 + alpha)\n\n            for p in group['params']:\n                params_with_grad.append(p)\n                w_list.append(p)\n                #v_list.append(p)\n                d_p_list.append(p.grad)\n                state = self.state[p]\n\n            for i, param in enumerate(params_with_grad):\n                d_p = d_p_list[i]\n                w_t = w_list[i]\n\n                w_t1 = param - lr*d_p\n                param.data = (1 + gamma)*w_t1.detach() - gamma*w_t - lr2*d_p\n\n                w_list[i] = w_t1\n\n            for p in params_with_grad:\n                state = self.state[p]\n\n        return loss","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResBlock(nn.Module):\n  \"\"\"\n  Residual block of 2 conv layers:\n  Conv -> Norm -> Act -> Conv -> Norm -> Act\n     |__[Optional: 1x1 Conv -> Norm]__|\n  \"\"\"\n  def __init__(self, in_channels, mid_channels, out_channels, downsample=None):\n    super().__init__()\n    self.downsample = isinstance(downsample, int)\n    self.conv1 = nn.Conv2d(in_channels, mid_channels, 3, padding=1, stride=(downsample or 1))\n    self.norm1 = nn.BatchNorm2d(mid_channels)\n    self.act1 = nn.ReLU()\n    self.conv2 = nn.Conv2d(mid_channels, out_channels, 3, padding=1)\n    self.norm2 = nn.BatchNorm2d(out_channels)\n    self.act2 = nn.ReLU()\n    if self.downsample:\n      self.convp = nn.Conv2d(in_channels, out_channels, 1, padding=0, stride=downsample)\n      self.normp = nn.BatchNorm2d(out_channels)\n    \n  def forward(self, x):\n    x_ = self.act1(self.norm1(self.conv1(x)))\n    x_ = self.norm2(self.conv2(x_))\n    if self.downsample:\n      x = self.normp(self.convp(x))\n    x = x + x_\n    return self.act2(x)\n\n    \nclass ResNet(nn.Module):\n  def __init__(self, channels=[16,32,64],\n               num_classes=10):\n    super().__init__()\n    self.conv1 = nn.Conv2d(3, channels[0], 3, padding=1)\n    self.block1 = nn.Sequential(\n                                *[\n                                ResBlock(channels[0], channels[0], channels[0])\n                                for i in range(5)\n                                ])\n    self.block2 = nn.Sequential(ResBlock(channels[0], channels[1], channels[1], downsample=2),\n                                *[\n                                ResBlock(channels[1], channels[1], channels[1])\n                                for i in range(4)\n                                ])\n    self.block3 = nn.Sequential(ResBlock(channels[1], channels[2], channels[2], downsample=2),\n                                *[\n                                ResBlock(channels[2], channels[2], channels[2])\n                                for i in range(4)\n                                ])\n    self.pool = nn.AvgPool2d(8)\n    self.flat_channels = channels[2]\n    self.fc = nn.Linear(channels[2], num_classes)\n    self.prob = nn.Softmax(dim=1)\n\n  def forward(self, x):\n    B = x.shape[0]\n    x = self.conv1(x)\n    x = self.block1(x)\n    x = self.block2(x)\n    x = self.block3(x)\n    x = self.pool(x)\n    x = torch.flatten(x,1)\n    x = self.fc(x)\n    return x","metadata":{"id":"7elYArKHGdy8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plotLosses(epochs, Loss, title):\n    plt.figure(figsize=(10,6))\n    plt.title(title)\n    plt.plot(epochs, Loss, label = \"Loss\")\n    plt.legend()\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.savefig(title + '.png')","metadata":{"id":"i67P8N7kGfhK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = ResNet().to(device)\nModelName = 'ResNet'\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\nopt = 'SGD'","metadata":{"id":"D9zOZ_yLGjPw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = []\nn_total_steps = len(train_loader)\ntrain_loss_average = torch.zeros(num_epochs)\nvalid_loss_average = torch.zeros(num_epochs)\ntrain_accuracy = torch.zeros(num_epochs)\nvalid_accuracy = torch.zeros(num_epochs)\nscheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[150,225], gamma=0.1)","metadata":{"id":"Td46OK4XGq5y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def train():\n\n    model.train()\n    running_train_loss = 0\n    correct = 0\n    total = 0\n\n    for i, (images, labels) in enumerate(train_loader):\n        images = images.to(device)\n        labels = labels.to(device)\n\n        # Forward pass\n        outputs = model(images)\n        train_step_loss = criterion(outputs, labels)\n\n        # Backward and optimize\n        optimizer.zero_grad()\n        train_step_loss.backward()\n        optimizer.step()\n\n        running_train_loss += train_step_loss.item()\n\n        #predictions\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    accuracy = 100.*correct/total\n\n    #get the training losses and accuracies\n    train_loss_average[epoch] = running_train_loss/len(train_loader)\n    train_accuracy[epoch] = accuracy\n\n    print(f'Training Loss: {running_train_loss/len(train_loader)}\\t \\\n            Training accuracy: {train_accuracy[epoch]}')","metadata":{"id":"SkRQlpLfGvpd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test():\n    model.eval()\n\n    running_valid_loss = 0\n    correct = 0\n    total = 0\n\n    #validation loop\n    with torch.no_grad():\n        for i, (images, labels) in enumerate(test_loader):\n            images = images.to(device)\n            labels = labels.to(device)\n\n            outputs = model(images)\n            valid_step_loss = criterion(outputs, labels)\n\n            running_valid_loss += valid_step_loss.item()\n\n            #predictions\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    accuracy = 100.*correct/total\n\n    #get the validation losses\n    valid_loss_average[epoch] = running_valid_loss/len(test_loader)\n    valid_accuracy[epoch] = accuracy\n\n\n    print(f'Validation Loss: {running_valid_loss/len(test_loader)}\\t \\\n            Validation accuracy: {valid_accuracy[epoch]}\\t \\\n            LR:{curr_lr}')","metadata":{"id":"9d2pgrFpG0H1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_time = time.time()\nfor epoch in range(num_epochs):\n    print(f'Epoch: {epoch+1}')\n\n    #get the current learning rate\n    curr_lr = optimizer.param_groups[0]['lr']\n    \n    train()\n    test()\n\n    epochs.append(epoch)\n\n    #step the learning rate scheduler\n    scheduler.step()\n\n\nprint(\"--- %s seconds ---\" % (time.time() - start_time))\nprint('Finished Training')","metadata":{"id":"RP5vDVN3G3Qe","outputId":"1a838e0c-bdda-49f4-a64c-7384c626f727"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    n_correct = 0\n    n_samples = 0\n    n_class_correct = [0 for i in range(10)]\n    n_class_samples = [0 for i in range(10)]\n    for images, labels in test_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        outputs = model(images)\n        # max returns (value ,index)\n        _, predicted = torch.max(outputs, 1)\n        n_samples += labels.size(0)\n        n_correct += (predicted == labels).sum().item()\n\n        for label, prediction in zip(labels, predicted):\n            if (label == prediction):\n                n_class_correct[label] += 1\n            n_class_samples[label] += 1\n\n    acc = 100.0 * n_correct / n_samples\n    print(f'Accuracy of the network: {acc} %')\n\n    for i in range(10):\n        class_acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n        print(f'Accuracy of {classes[i]}: {class_acc} %')","metadata":{"id":"6sGdNtCtG670"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plotLosses(epochs, Loss, title):\n    plt.figure(figsize=(10,6))\n    plt.title(title)\n    plt.plot(epochs, Loss, label = \"Loss\")\n    plt.legend()\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.savefig(title + '.png')","metadata":{"id":"v2pld5IsG-xu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot the loss diagrams and save\nplt.figure(figsize=(10,6))\nplt.title(f'ResNet-{opt} lr:{learning_rate} acc:{acc}')\nplt.plot(epochs, train_loss_average, label = \"Training loss\")\nplt.plot(epochs, valid_loss_average, label = 'Validation loss')\nplt.legend()\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.savefig(f'ResNet-Loss-{opt}_lr_{learning_rate}_acc_{acc}.png')\n\n\n#plot the loss diagrams and save\nplt.figure(figsize=(10,6))\nplt.title(f'ResNet-{opt}_lr_{learning_rate}_acc_{acc}')\nplt.plot(epochs, train_accuracy, label = \"Training Accuracy\")\nplt.plot(epochs, valid_accuracy, label = 'Validation Accuracy')\nplt.legend()\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.savefig(f'ResNet-Accuracy-{opt}_lr_{learning_rate}_acc_{acc}.png')\n\nPATH = f'./ResNet-{opt}_lr_{learning_rate}_acc_{acc}.pth'\ntorch.save(model.state_dict(), PATH)","metadata":{"id":"BroD1VOSHBf8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path\n\ndf = pd.DataFrame(train_loss_average, columns=['train_loss'], index=[i for i in range(1,301)])\ndf.to_csv(f'{ModelName}-{opt}-{learning_rate}-train_loss.csv')\n\ndf = pd.DataFrame(valid_loss_average, columns=['valid_loss'], index=[i for i in range(1,301)])\ndf.to_csv(f'{ModelName}-{opt}-{learning_rate}-val_loss.csv')\n\n\ndf = pd.DataFrame(train_accuracy, columns=['train_accuracy'], index=[i for i in range(1,301)])\ndf.to_csv(f'{ModelName}-{opt}-{learning_rate}-train_acc.csv')\n\n\ndf = pd.DataFrame(valid_accuracy, columns=['valid_accuracy'], index=[i for i in range(1,301)])\ndf.to_csv(f'{ModelName}-{opt}-{learning_rate}-val_acc.csv')","metadata":{"id":"DLIpTQ7NRTam"},"execution_count":null,"outputs":[]}]}
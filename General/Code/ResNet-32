{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ResNet-32","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOEtT+sbzDJi/igOMM6TCR1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["\"\"\"\n","Residual Network (ResNet). We train a ResNet (7) with 32 convolutional layers. The ResNet-32\n","has a sequence of 15 residual blocks: the first 5 blocks have an output of shape 32 × 32 × 16, the\n","following 5 blocks have an output of shape 16×16×32 and the last 5 blocks have an output of shape\n","8×8×64. On top of these blocks, there is a 2×2 average pooling layer with stride of 2, followed by\n","a output layer of size 10 with softmax non-linearity. The ResNet-32 has ≈467k trainable parameters\n","in total.\n","\"\"\""],"metadata":{"id":"HmMo1fAVRoHU"}},{"cell_type":"code","source":["import torch\n","from torch import nn\n","\n","class ResBlock(nn.Module):\n","  \"\"\"\n","  Residual block of 2 conv layers:\n","  Conv -> Norm -> Act -> Conv -> Norm -> Act\n","     |__[Optional: 1x1 Conv -> Norm]__|\n","  \"\"\"\n","  def __init__(self, in_channels, mid_channels, out_channels, downsample=None):\n","    super().__init__()\n","    self.downsample = isinstance(downsample, int)\n","    self.conv1 = nn.Conv2d(in_channels, mid_channels, 3, padding=1, stride=(downsample or 1))\n","    self.norm1 = nn.BatchNorm2d(mid_channels)\n","    self.act1 = nn.ReLU()\n","    self.conv2 = nn.Conv2d(mid_channels, out_channels, 3, padding=1)\n","    self.norm2 = nn.BatchNorm2d(out_channels)\n","    self.act2 = nn.ReLU()\n","    if self.downsample:\n","      self.convp = nn.Conv2d(in_channels, out_channels, 1, padding=0, stride=downsample)\n","      self.normp = nn.BatchNorm2d(out_channels)\n","    \n","  def forward(self, x):\n","    x_ = self.act1(self.norm1(self.conv1(x)))\n","    x_ = self.norm2(self.conv2(x_))\n","    if self.downsample:\n","      x = self.normp(self.convp(x))\n","    x += x_\n","    return self.act2(x)\n","\n","    \n","class ResNet(nn.Module):\n","  def __init__(self, channels=[16,32,64],\n","               num_classes=10):\n","    super().__init__()\n","    self.conv1 = nn.Conv2d(3, channels[0], 3, padding=1)\n","    self.block1 = nn.Sequential(\n","                                *[\n","                                ResBlock(channels[0], channels[0], channels[0])\n","                                for i in range(5)\n","                                ])\n","    self.block2 = nn.Sequential(ResBlock(channels[0], channels[1], channels[1], downsample=2),\n","                                *[\n","                                ResBlock(channels[1], channels[1], channels[1])\n","                                for i in range(4)\n","                                ])\n","    self.block3 = nn.Sequential(ResBlock(channels[1], channels[2], channels[2], downsample=2),\n","                                *[\n","                                ResBlock(channels[2], channels[2], channels[2])\n","                                for i in range(4)\n","                                ])\n","    self.pool = nn.AvgPool2d(8)\n","    self.flat_channels = channels[2]\n","    self.fc = nn.Linear(channels[2], num_classes)\n","    self.prob = nn.Softmax(dim=1)\n","\n","  def forward(self, x):\n","    B = x.shape[0]\n","    x = self.conv1(x)\n","    x = self.block1(x)\n","    x = self.block2(x)\n","    x = self.block3(x)\n","    print(x.shape)\n","    x = self.pool(x)\n","    print(x.shape)\n","    # x = x.flatten()\n","    x=torch.flatten(x,1)\n","    print(x.shape)\n","    x = self.fc(x)\n","    # print(x.shape)\n","    x = self.prob(x)\n","    return x\n","    "],"metadata":{"id":"VwIgKQ_cRmns","executionInfo":{"status":"ok","timestamp":1648215234919,"user_tz":0,"elapsed":200,"user":{"displayName":"Conor Chalcroft","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18228664345795957942"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["#Quick Test\n","model = ResNet()\n","out = model(torch.rand(128,3,32,32))\n","print(out)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n1HLvniSRypv","executionInfo":{"status":"ok","timestamp":1648215237567,"user_tz":0,"elapsed":1041,"user":{"displayName":"Conor Chalcroft","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18228664345795957942"}},"outputId":"095eace2-2220-44ca-b40c-df3f88a12394"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([128, 64, 8, 8])\n","torch.Size([128, 64, 1, 1])\n","torch.Size([128, 64])\n","tensor([[0.0583, 0.2352, 0.0254,  ..., 0.1108, 0.0594, 0.0327],\n","        [0.0365, 0.2988, 0.0128,  ..., 0.1220, 0.0383, 0.0282],\n","        [0.0388, 0.2685, 0.0174,  ..., 0.1180, 0.0393, 0.0215],\n","        ...,\n","        [0.0403, 0.2531, 0.0167,  ..., 0.1233, 0.0448, 0.0320],\n","        [0.0471, 0.2415, 0.0187,  ..., 0.1070, 0.0475, 0.0337],\n","        [0.0538, 0.2776, 0.0150,  ..., 0.1063, 0.0391, 0.0263]],\n","       grad_fn=<SoftmaxBackward0>)\n"]}]},{"cell_type":"code","source":["\" Load CIFAR10 Data \"\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","batch_size = 128\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n","                                          shuffle=True, num_workers=2)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                       download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n","                                         shuffle=False, num_workers=2)\n","\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PwO_ZtVJltef","executionInfo":{"status":"ok","timestamp":1648215241737,"user_tz":0,"elapsed":2118,"user":{"displayName":"Conor Chalcroft","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18228664345795957942"}},"outputId":"bf7e9dc0-af66-4af1-a2e2-264356d0bc86"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","source":["import torch.optim as optim\n","\n","net = ResNet()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"],"metadata":{"id":"Po6rudb1sz_k","executionInfo":{"status":"ok","timestamp":1648215202705,"user_tz":0,"elapsed":257,"user":{"displayName":"Conor Chalcroft","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18228664345795957942"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["for epoch in range(2):  # loop over the dataset multiple times\n","\n","    running_loss = 0.0\n","    for i, data in enumerate(trainloader, 0):\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data\n","\n","        # with torch.autograd.set_detect_anomaly(True):\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = net(inputs)\n","        # print(\"outputs\", outputs)\n","        # print(labels)\n","        loss = criterion(outputs, labels)\n","        print(loss)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","        if i % 2000 == 1999:    # print every 2000 mini-batches\n","            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n","            running_loss = 0.0\n","\n","print('Finished Training')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":476},"id":"7hCuA6oJs3T1","executionInfo":{"status":"error","timestamp":1648215206110,"user_tz":0,"elapsed":1386,"user":{"displayName":"Conor Chalcroft","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18228664345795957942"}},"outputId":"d71781a8-ede3-4a31-8f9b-b582cb97fee8"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([128, 64, 8, 8])\n","torch.Size([128, 64, 1, 1])\n","torch.Size([128, 64])\n","tensor(2.3123, grad_fn=<NllLossBackward0>)\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-850227c5d34e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [128, 64, 8, 8]], which is output 0 of AddBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."]}]}]}
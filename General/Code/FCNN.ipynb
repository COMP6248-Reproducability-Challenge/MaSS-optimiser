{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ssl\n",
    "import seaborn as sns\n",
    "import time\n",
    "import torchbearer\n",
    "\n",
    "sns.set_theme()\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "num_epochs = 150\n",
    "batch_size = 64\n",
    "learning_rate = 0.01"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dataset has PILImage images of range [0, 1].\n",
    "# We transform them to Tensors of normalized range [-1, 1]\n",
    "'''\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "'''\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.view(-1)),\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                         shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class FCNClass(nn.Module):\n",
    "    def __init__(self):\n",
    "        # input: 784 Dimensional Vectors as input\n",
    "        super(FCNClass, self).__init__()\n",
    "\n",
    "        # layer 1 (784-100)\n",
    "        # Hidden Layer\n",
    "        # Dropout Layer with keep prob 0.5\n",
    "        self.hidden1 = nn.Sequential(\n",
    "                        nn.Linear(784, 100),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(p=0.5)\n",
    "        )\n",
    "\n",
    "        # Layer 2 (100-100)\n",
    "        # Hidden Layer\n",
    "        # Dropout Layer with keep prob 0.5\n",
    "        self.hidden2 = nn.Sequential(\n",
    "                        nn.Linear(100, 100),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(p=0.5)\n",
    "        )\n",
    "\n",
    "        # Layer 3 (100-10)\n",
    "        # Hidden Layer\n",
    "        # Dropout Layer with keep prob 0.5\n",
    "        self.hidden3 = nn.Sequential(\n",
    "                        nn.Linear(100, 100),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(p=0.5)\n",
    "        )\n",
    "\n",
    "        # Layer 4 (100-10)\n",
    "        # Hidden Layer\n",
    "        # Dropout Layer with keep prob 0.5\n",
    "        self.output = nn.Sequential(\n",
    "                        nn.Linear(100, 10),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(p=0.5)\n",
    "        )\n",
    "        # 10 softmax activated output neurons\n",
    "        self.outputLayer = nn.Softmax(dim=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        midLevel = self.hidden1(x)\n",
    "        midLevel = self.hidden2(midLevel)\n",
    "        midLevel = self.hidden3(midLevel)\n",
    "        output   = self.output(midLevel)\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def plotLosses(epochs, Loss, title):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.title(title)\n",
    "    plt.plot(epochs, Loss, label = \"Loss\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "model = FCNClass().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, nesterov=True, momentum=0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "train_loss_history = []\n",
    "valid_loss_history = []\n",
    "epochs = []\n",
    "n_total_steps = len(train_loader)\n",
    "train_loss_average = torch.zeros(num_epochs)\n",
    "valid_loss_average = torch.zeros(num_epochs)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[60,120], gamma=0.1)\n",
    "start_time = time.time()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\t             Training Loss: 2.0602282459801957\t             Validation Loss:1.4145795456163444\t             LR:0.01\n",
      "Epoch 1\t             Training Loss: 1.7741011254060497\t             Validation Loss:1.1633448490671292\t             LR:0.01\n",
      "Epoch 2\t             Training Loss: 1.7109019893573036\t             Validation Loss:1.1046266441891908\t             LR:0.01\n",
      "Epoch 3\t             Training Loss: 1.6841591170855932\t             Validation Loss:1.043050306617834\t             LR:0.01\n",
      "Epoch 4\t             Training Loss: 1.672954346833707\t             Validation Loss:1.019515394405195\t             LR:0.01\n",
      "Epoch 5\t             Training Loss: 1.6609879190733692\t             Validation Loss:0.9961771346201562\t             LR:0.01\n",
      "Epoch 6\t             Training Loss: 1.645923418785209\t             Validation Loss:0.9920342735424164\t             LR:0.01\n",
      "Epoch 7\t             Training Loss: 1.6477968791908801\t             Validation Loss:0.9734699524891605\t             LR:0.01\n",
      "Epoch 8\t             Training Loss: 1.6399949416677073\t             Validation Loss:0.9902177635271838\t             LR:0.01\n",
      "Epoch 9\t             Training Loss: 1.6388968601663991\t             Validation Loss:0.9668680315564393\t             LR:0.01\n",
      "Epoch 10\t             Training Loss: 1.6374127867379422\t             Validation Loss:0.9557542216246295\t             LR:0.01\n",
      "Epoch 11\t             Training Loss: 1.6304430176200135\t             Validation Loss:0.9596025419842665\t             LR:0.01\n",
      "Epoch 12\t             Training Loss: 1.6251850328974125\t             Validation Loss:0.9627298082515692\t             LR:0.01\n",
      "Epoch 13\t             Training Loss: 1.6264582700820873\t             Validation Loss:0.9838632717254056\t             LR:0.01\n",
      "Epoch 14\t             Training Loss: 1.623829008165453\t             Validation Loss:0.9511708643785708\t             LR:0.01\n",
      "Epoch 15\t             Training Loss: 1.6151855703610092\t             Validation Loss:0.9718186847723214\t             LR:0.01\n",
      "Epoch 16\t             Training Loss: 1.6079157384982241\t             Validation Loss:0.9464895740436141\t             LR:0.01\n",
      "Epoch 17\t             Training Loss: 1.6183743265900277\t             Validation Loss:0.9494109510616132\t             LR:0.01\n",
      "Epoch 18\t             Training Loss: 1.6066891246004653\t             Validation Loss:0.9495683099813522\t             LR:0.01\n",
      "Epoch 19\t             Training Loss: 1.6148600336839396\t             Validation Loss:0.9340663305513418\t             LR:0.01\n",
      "Epoch 20\t             Training Loss: 1.610482102263965\t             Validation Loss:0.9464123940012258\t             LR:0.01\n",
      "Epoch 21\t             Training Loss: 1.615918987214184\t             Validation Loss:0.9488413679371973\t             LR:0.01\n",
      "Epoch 22\t             Training Loss: 1.6131564184292546\t             Validation Loss:0.938960913639919\t             LR:0.01\n",
      "Epoch 23\t             Training Loss: 1.6077912053319692\t             Validation Loss:0.9432515839862216\t             LR:0.01\n",
      "Epoch 24\t             Training Loss: 1.6018771996249015\t             Validation Loss:0.9250948246876904\t             LR:0.01\n",
      "Epoch 25\t             Training Loss: 1.6080283819993675\t             Validation Loss:0.9232141652684303\t             LR:0.01\n",
      "Epoch 26\t             Training Loss: 1.6060957290978828\t             Validation Loss:0.937252501013932\t             LR:0.01\n",
      "Epoch 27\t             Training Loss: 1.603864853061847\t             Validation Loss:0.9399851093626326\t             LR:0.01\n",
      "Epoch 28\t             Training Loss: 1.6110902433710566\t             Validation Loss:0.9358028200021975\t             LR:0.01\n",
      "Epoch 29\t             Training Loss: 1.598213510599726\t             Validation Loss:0.9286317221677987\t             LR:0.01\n",
      "Epoch 30\t             Training Loss: 1.6045086828630362\t             Validation Loss:0.9139452595619639\t             LR:0.01\n",
      "Epoch 31\t             Training Loss: 1.5959408377279352\t             Validation Loss:0.9237807427242304\t             LR:0.01\n",
      "Epoch 32\t             Training Loss: 1.6008143862173247\t             Validation Loss:0.925575856949873\t             LR:0.01\n",
      "Epoch 33\t             Training Loss: 1.597514181884367\t             Validation Loss:0.927559026487314\t             LR:0.01\n",
      "Epoch 34\t             Training Loss: 1.5946027966958882\t             Validation Loss:0.9266504208753064\t             LR:0.01\n",
      "Epoch 35\t             Training Loss: 1.5973576790234174\t             Validation Loss:0.9211822755777153\t             LR:0.01\n",
      "Epoch 36\t             Training Loss: 1.5954517431096482\t             Validation Loss:0.9157653773666188\t             LR:0.01\n",
      "Epoch 37\t             Training Loss: 1.5974966925598666\t             Validation Loss:0.9226506253716292\t             LR:0.01\n",
      "Epoch 38\t             Training Loss: 1.6036065435612887\t             Validation Loss:0.9154057350887614\t             LR:0.01\n",
      "Epoch 39\t             Training Loss: 1.5965965390205383\t             Validation Loss:0.9156597799556271\t             LR:0.01\n",
      "Epoch 40\t             Training Loss: 1.5982329160419864\t             Validation Loss:0.939615718118704\t             LR:0.01\n",
      "Epoch 41\t             Training Loss: 1.5888996689812716\t             Validation Loss:0.9310343755278617\t             LR:0.01\n",
      "Epoch 42\t             Training Loss: 1.5967342270208573\t             Validation Loss:0.9314037200751578\t             LR:0.01\n",
      "Epoch 43\t             Training Loss: 1.5923705844482634\t             Validation Loss:0.9135750285379446\t             LR:0.01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/dr/704qjz3n21lgqk009dttw33w0000gn/T/ipykernel_5448/786599304.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0;31m#trainng loop\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m     \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mimages\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_loader\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m         \u001B[0mimages\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mimages\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m         \u001B[0mlabels\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    528\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sampler_iter\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    529\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 530\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    531\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    532\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIterable\u001B[0m \u001B[0;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    568\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    569\u001B[0m         \u001B[0mindex\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# may raise StopIteration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 570\u001B[0;31m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_fetcher\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfetch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# may raise StopIteration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    571\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pin_memory\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    572\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_utils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\u001B[0m in \u001B[0;36mfetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     47\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mfetch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     48\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mauto_collation\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 49\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     50\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     51\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     47\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mfetch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     48\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mauto_collation\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 49\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     50\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     51\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/datasets/mnist.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, index)\u001B[0m\n\u001B[1;32m    143\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    144\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransform\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 145\u001B[0;31m             \u001B[0mimg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    146\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    147\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtarget_transform\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/transforms/transforms.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, img)\u001B[0m\n\u001B[1;32m     93\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mimg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     94\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mt\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransforms\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 95\u001B[0;31m             \u001B[0mimg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     96\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mimg\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     97\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/transforms/transforms.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, pic)\u001B[0m\n\u001B[1;32m    133\u001B[0m             \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mConverted\u001B[0m \u001B[0mimage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    134\u001B[0m         \"\"\"\n\u001B[0;32m--> 135\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_tensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpic\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    136\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    137\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__repr__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/transforms/functional.py\u001B[0m in \u001B[0;36mto_tensor\u001B[0;34m(pic)\u001B[0m\n\u001B[1;32m    145\u001B[0m     \u001B[0;31m# handle PIL Image\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    146\u001B[0m     \u001B[0mmode_to_nptype\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m\"I\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mint32\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"I;16\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mint16\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"F\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat32\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 147\u001B[0;31m     \u001B[0mimg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_numpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpic\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode_to_nptype\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpic\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0muint8\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    148\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    149\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mpic\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"1\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/PIL/Image.py\u001B[0m in \u001B[0;36m__array__\u001B[0;34m(self, dtype)\u001B[0m\n\u001B[1;32m    701\u001B[0m             \u001B[0m__array_interface__\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnew\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    702\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 703\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mArrayData\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    704\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    705\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__getstate__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    running_train_loss = 0.0\n",
    "    running_valid_loss = 0.0\n",
    "    #trainng loop\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        train_step_loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        train_step_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_train_loss += train_step_loss.item()\n",
    "\n",
    "    #get the training losses\n",
    "    train_loss_average[epoch] = running_train_loss/len(train_loader)\n",
    "    train_loss_history.append(train_step_loss.item())\n",
    "\n",
    "    #validation loop\n",
    "    model.eval()\n",
    "    for i, (images, labels) in enumerate(test_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        valid_step_loss = criterion(outputs, labels)\n",
    "\n",
    "        running_valid_loss += valid_step_loss.item()\n",
    "\n",
    "    #get the validation losses\n",
    "    valid_loss_average[epoch] = running_valid_loss/len(test_loader)\n",
    "    valid_loss_history.append(valid_step_loss.item())\n",
    "    epochs.append(epoch)\n",
    "\n",
    "    #get the current learning rate\n",
    "    curr_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    #step the learning rate scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f'Epoch {epoch}\\t \\\n",
    "            Training Loss: {running_train_loss/len(train_loader)}\\t \\\n",
    "            Validation Loss:{running_valid_loss/len(test_loader)}\\t \\\n",
    "            LR:{curr_lr}')\n",
    "\n",
    "\n",
    "#plot the loss diagrams\n",
    "plotLosses(epochs, train_loss_average, 'training loss graph for cnn-nesterov')\n",
    "plotLosses(epochs, valid_loss_average, 'validation loss graph for cnn-nesterov')\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title('CNN nesterov')\n",
    "plt.plot(epochs, train_loss_average, label = \"Training loss\")\n",
    "plt.plot(epochs, valid_loss_average, label = 'Validation loss')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('Finished Training')\n",
    "\n",
    "PATH = './cnn-nesterov.pth'\n",
    "torch.save(model.state_dict(), PATH)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the 10000 test images: {acc} %')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(epochs))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ssl\n",
    "import seaborn as sns\n",
    "import time\n",
    "from MaSS import MaSS\n",
    "import torchbearer\n",
    "\n",
    "sns.set_theme()\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "num_epochs = 150\n",
    "batch_size = 64\n",
    "learning_rate = 0.005"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dataset has PILImage images of range [0, 1].\n",
    "# We transform them to Tensors of normalized range [-1, 1]\n",
    "'''\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "'''\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.view(-1)),\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                         shuffle=False)\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "class FCNClass(nn.Module):\n",
    "    def __init__(self):\n",
    "        # input: 784 Dimensional Vectors as input\n",
    "        super(FCNClass, self).__init__()\n",
    "\n",
    "        # layer 1 (784-100)\n",
    "        # Hidden Layer\n",
    "        # Dropout Layer with keep prob 0.5\n",
    "        self.hidden1 = nn.Sequential(\n",
    "                        nn.Linear(784, 100),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(p=0.5)\n",
    "        )\n",
    "\n",
    "        # Layer 2 (100-100)\n",
    "        # Hidden Layer\n",
    "        # Dropout Layer with keep prob 0.5\n",
    "        self.hidden2 = nn.Sequential(\n",
    "                        nn.Linear(100, 100),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(p=0.5)\n",
    "        )\n",
    "\n",
    "        # Layer 3 (100-100)\n",
    "        # Hidden Layer\n",
    "        # Dropout Layer with keep prob 0.5\n",
    "        self.hidden3 = nn.Sequential(\n",
    "                        nn.Linear(100, 100),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(p=0.5)\n",
    "        )\n",
    "\n",
    "        # Layer 4 (100-10)\n",
    "        # Hidden Layer\n",
    "        # Dropout Layer with keep prob 0.5\n",
    "        self.output = nn.Sequential(\n",
    "                        nn.Linear(100, 10),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(p=0.5)\n",
    "        )\n",
    "        # 10 softmax activated output neurons\n",
    "        self.outputLayer = nn.Softmax(dim=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        midLevel = self.hidden1(x)\n",
    "        midLevel = self.hidden2(midLevel)\n",
    "        midLevel = self.hidden3(midLevel)\n",
    "        output   = self.output(midLevel)\n",
    "        return output\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "model = FCNClass().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = MaSS(model.parameters(), lr=learning_rate, alpha=0.05, kappa_t=3)\n",
    "opt = \"MaSS\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "epochs = []\n",
    "n_total_steps = len(train_loader)\n",
    "train_loss_average = torch.zeros(num_epochs)\n",
    "valid_loss_average = torch.zeros(num_epochs)\n",
    "train_accuracy = torch.zeros(num_epochs)\n",
    "valid_accuracy = torch.zeros(num_epochs)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[60,120], gamma=0.1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "\n",
    "def train():\n",
    "\n",
    "    model.train()\n",
    "    running_train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        train_step_loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        train_step_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_train_loss += train_step_loss.item()\n",
    "\n",
    "        #predictions\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100.*correct/total\n",
    "\n",
    "    #get the training losses and accuracies\n",
    "    train_loss_average[epoch] = running_train_loss/len(train_loader)\n",
    "    train_accuracy[epoch] = accuracy\n",
    "\n",
    "    print(f'Training Loss: {running_train_loss/len(train_loader)}\\t \\\n",
    "            Training accuracy: {train_accuracy[epoch]}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    running_valid_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    #validation loop\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(test_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            valid_step_loss = criterion(outputs, labels)\n",
    "\n",
    "            running_valid_loss += valid_step_loss.item()\n",
    "\n",
    "            #predictions\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100.*correct/total\n",
    "\n",
    "    #get the validation losses\n",
    "    valid_loss_average[epoch] = running_valid_loss/len(test_loader)\n",
    "    valid_accuracy[epoch] = accuracy\n",
    "\n",
    "\n",
    "    print(f'Validation Loss: {running_valid_loss/len(test_loader)}\\t \\\n",
    "            Validation accuracy: {valid_accuracy[epoch]}\\t \\\n",
    "            LR:{curr_lr}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Training Loss: 2.2931436686627644\t             Training accuracy: 13.324999809265137\n",
      "Validation Loss: 2.2516074772853\t             Validation accuracy: 39.900001525878906\t             LR:0.005\n",
      "Epoch: 2\n",
      "Training Loss: 2.2006224034183317\t             Training accuracy: 20.8700008392334\n",
      "Validation Loss: 2.011707569383512\t             Validation accuracy: 52.849998474121094\t             LR:0.005\n",
      "Epoch: 3\n",
      "Training Loss: 2.0725866591752466\t             Training accuracy: 26.979999542236328\n",
      "Validation Loss: 1.7727644694079259\t             Validation accuracy: 58.84000015258789\t             LR:0.005\n",
      "Epoch: 4\n",
      "Training Loss: 1.9383024636870507\t             Training accuracy: 32.67333221435547\n",
      "Validation Loss: 1.5260147866170117\t             Validation accuracy: 67.7699966430664\t             LR:0.005\n",
      "Epoch: 5\n",
      "Training Loss: 1.8362291812388374\t             Training accuracy: 35.698333740234375\n",
      "Validation Loss: 1.3446311821603472\t             Validation accuracy: 69.8499984741211\t             LR:0.005\n",
      "Epoch: 6\n",
      "Training Loss: 1.769614250802282\t             Training accuracy: 37.413333892822266\n",
      "Validation Loss: 1.2242315369806471\t             Validation accuracy: 70.7699966430664\t             LR:0.005\n",
      "Epoch: 7\n",
      "Training Loss: 1.7280541381347916\t             Training accuracy: 38.18000030517578\n",
      "Validation Loss: 1.1372616742826571\t             Validation accuracy: 71.38999938964844\t             LR:0.005\n",
      "Epoch: 8\n",
      "Training Loss: 1.694726838994382\t             Training accuracy: 38.8849983215332\n",
      "Validation Loss: 1.069205733241549\t             Validation accuracy: 71.9800033569336\t             LR:0.005\n",
      "Epoch: 9\n",
      "Training Loss: 1.6710794489266776\t             Training accuracy: 39.279998779296875\n",
      "Validation Loss: 1.0281039153694347\t             Validation accuracy: 72.19000244140625\t             LR:0.005\n",
      "Epoch: 10\n",
      "Training Loss: 1.6458368422125957\t             Training accuracy: 39.96666717529297\n",
      "Validation Loss: 0.9831145439937616\t             Validation accuracy: 72.52999877929688\t             LR:0.005\n",
      "Epoch: 11\n",
      "Training Loss: 1.6382951191239266\t             Training accuracy: 40.16166687011719\n",
      "Validation Loss: 0.9638128181931319\t             Validation accuracy: 72.81999969482422\t             LR:0.005\n",
      "Epoch: 12\n",
      "Training Loss: 1.6248007771302897\t             Training accuracy: 40.29999923706055\n",
      "Validation Loss: 0.9443117581355344\t             Validation accuracy: 73.20999908447266\t             LR:0.005\n",
      "Epoch: 13\n",
      "Training Loss: 1.6153696549218346\t             Training accuracy: 40.5533332824707\n",
      "Validation Loss: 0.9202178447109879\t             Validation accuracy: 73.2699966430664\t             LR:0.005\n",
      "Epoch: 14\n",
      "Training Loss: 1.6044154455666857\t             Training accuracy: 40.82833480834961\n",
      "Validation Loss: 0.9094796340177014\t             Validation accuracy: 73.80999755859375\t             LR:0.005\n",
      "Epoch: 15\n",
      "Training Loss: 1.599579530229955\t             Training accuracy: 40.86166763305664\n",
      "Validation Loss: 0.8866858890481816\t             Validation accuracy: 73.91999816894531\t             LR:0.005\n",
      "Epoch: 16\n",
      "Training Loss: 1.5986857711633384\t             Training accuracy: 40.731666564941406\n",
      "Validation Loss: 0.8839566398198437\t             Validation accuracy: 74.12999725341797\t             LR:0.005\n",
      "Epoch: 17\n",
      "Training Loss: 1.5869223733446491\t             Training accuracy: 41.11000061035156\n",
      "Validation Loss: 0.8715249582840379\t             Validation accuracy: 74.33000183105469\t             LR:0.005\n",
      "Epoch: 18\n",
      "Training Loss: 1.5808331211492705\t             Training accuracy: 41.198333740234375\n",
      "Validation Loss: 0.8431733877036223\t             Validation accuracy: 74.44000244140625\t             LR:0.005\n",
      "Epoch: 19\n",
      "Training Loss: 1.5711226983111042\t             Training accuracy: 41.393333435058594\n",
      "Validation Loss: 0.8454252050560751\t             Validation accuracy: 74.48999786376953\t             LR:0.005\n",
      "Epoch: 20\n",
      "Training Loss: 1.5617673217869008\t             Training accuracy: 41.688331604003906\n",
      "Validation Loss: 0.8310769606547751\t             Validation accuracy: 74.7300033569336\t             LR:0.005\n",
      "Epoch: 21\n",
      "Training Loss: 1.5585103896635173\t             Training accuracy: 41.654998779296875\n",
      "Validation Loss: 0.8051783336195976\t             Validation accuracy: 74.77999877929688\t             LR:0.005\n",
      "Epoch: 22\n",
      "Training Loss: 1.56281160736389\t             Training accuracy: 41.663333892822266\n",
      "Validation Loss: 0.8128472524843399\t             Validation accuracy: 74.94000244140625\t             LR:0.005\n",
      "Epoch: 23\n",
      "Training Loss: 1.5540700923405222\t             Training accuracy: 41.869998931884766\n",
      "Validation Loss: 0.797591429607124\t             Validation accuracy: 74.83999633789062\t             LR:0.005\n",
      "Epoch: 24\n",
      "Training Loss: 1.5495975720348643\t             Training accuracy: 41.869998931884766\n",
      "Validation Loss: 0.7956206969394806\t             Validation accuracy: 74.97000122070312\t             LR:0.005\n",
      "Epoch: 25\n",
      "Training Loss: 1.5562721182034214\t             Training accuracy: 41.59333419799805\n",
      "Validation Loss: 0.7962401683922786\t             Validation accuracy: 75.13999938964844\t             LR:0.005\n",
      "Epoch: 26\n",
      "Training Loss: 1.544611956900371\t             Training accuracy: 41.9283332824707\n",
      "Validation Loss: 0.7901629644214727\t             Validation accuracy: 75.11000061035156\t             LR:0.005\n",
      "Epoch: 27\n",
      "Training Loss: 1.5425381369428086\t             Training accuracy: 41.95500183105469\n",
      "Validation Loss: 0.789502617090371\t             Validation accuracy: 75.23999786376953\t             LR:0.005\n",
      "Epoch: 28\n",
      "Training Loss: 1.5380845119449884\t             Training accuracy: 42.06833267211914\n",
      "Validation Loss: 0.7835207496099411\t             Validation accuracy: 75.33000183105469\t             LR:0.005\n",
      "Epoch: 29\n",
      "Training Loss: 1.5426640773632887\t             Training accuracy: 41.810001373291016\n",
      "Validation Loss: 0.7773018667272701\t             Validation accuracy: 75.45999908447266\t             LR:0.005\n",
      "Epoch: 30\n",
      "Training Loss: 1.5365603104837413\t             Training accuracy: 42.005001068115234\n",
      "Validation Loss: 0.7708887716007841\t             Validation accuracy: 75.2699966430664\t             LR:0.005\n",
      "Epoch: 31\n",
      "Training Loss: 1.5363491223310866\t             Training accuracy: 42.00833511352539\n",
      "Validation Loss: 0.7533320619422159\t             Validation accuracy: 75.38999938964844\t             LR:0.005\n",
      "Epoch: 32\n",
      "Training Loss: 1.5314267603064906\t             Training accuracy: 42.29666519165039\n",
      "Validation Loss: 0.7676418615374595\t             Validation accuracy: 75.48999786376953\t             LR:0.005\n",
      "Epoch: 33\n",
      "Training Loss: 1.5286535376678907\t             Training accuracy: 42.20166778564453\n",
      "Validation Loss: 0.7580375859312191\t             Validation accuracy: 75.4800033569336\t             LR:0.005\n",
      "Epoch: 34\n",
      "Training Loss: 1.532158658575656\t             Training accuracy: 42.130001068115234\n",
      "Validation Loss: 0.7656874888262172\t             Validation accuracy: 75.70999908447266\t             LR:0.005\n",
      "Epoch: 35\n",
      "Training Loss: 1.5224144585859547\t             Training accuracy: 42.51166534423828\n",
      "Validation Loss: 0.7489377630364363\t             Validation accuracy: 75.58000183105469\t             LR:0.005\n",
      "Epoch: 36\n",
      "Training Loss: 1.5261012370398304\t             Training accuracy: 42.03666687011719\n",
      "Validation Loss: 0.7434961959055275\t             Validation accuracy: 75.58999633789062\t             LR:0.005\n",
      "Epoch: 37\n",
      "Training Loss: 1.527991519045474\t             Training accuracy: 42.0283317565918\n",
      "Validation Loss: 0.7464587751087869\t             Validation accuracy: 75.66999816894531\t             LR:0.005\n",
      "Epoch: 38\n",
      "Training Loss: 1.5218341361357968\t             Training accuracy: 42.30833435058594\n",
      "Validation Loss: 0.7417727471536891\t             Validation accuracy: 75.79000091552734\t             LR:0.005\n",
      "Epoch: 39\n",
      "Training Loss: 1.5173909477333525\t             Training accuracy: 42.28499984741211\n",
      "Validation Loss: 0.7276260699056516\t             Validation accuracy: 75.77999877929688\t             LR:0.005\n",
      "Epoch: 40\n",
      "Training Loss: 1.5179065206665983\t             Training accuracy: 42.426666259765625\n",
      "Validation Loss: 0.7343433119688824\t             Validation accuracy: 75.81999969482422\t             LR:0.005\n",
      "Epoch: 41\n",
      "Training Loss: 1.5214989134497734\t             Training accuracy: 42.223331451416016\n",
      "Validation Loss: 0.7374130360260132\t             Validation accuracy: 75.83999633789062\t             LR:0.005\n",
      "Epoch: 42\n",
      "Training Loss: 1.5136516935535584\t             Training accuracy: 42.43333435058594\n",
      "Validation Loss: 0.7359561001419261\t             Validation accuracy: 75.87999725341797\t             LR:0.005\n",
      "Epoch: 43\n",
      "Training Loss: 1.5195566769093594\t             Training accuracy: 42.276668548583984\n",
      "Validation Loss: 0.7288959838782146\t             Validation accuracy: 75.7699966430664\t             LR:0.005\n",
      "Epoch: 44\n",
      "Training Loss: 1.523196366041708\t             Training accuracy: 42.10333251953125\n",
      "Validation Loss: 0.7272252865657685\t             Validation accuracy: 75.87999725341797\t             LR:0.005\n",
      "Epoch: 45\n",
      "Training Loss: 1.510119665914507\t             Training accuracy: 42.45000076293945\n",
      "Validation Loss: 0.7236387822658393\t             Validation accuracy: 75.9000015258789\t             LR:0.005\n",
      "Epoch: 46\n",
      "Training Loss: 1.519131556884058\t             Training accuracy: 42.141666412353516\n",
      "Validation Loss: 0.7250222554252406\t             Validation accuracy: 75.72000122070312\t             LR:0.005\n",
      "Epoch: 47\n",
      "Training Loss: 1.5181412465536772\t             Training accuracy: 42.141666412353516\n",
      "Validation Loss: 0.7201473435778527\t             Validation accuracy: 75.87999725341797\t             LR:0.005\n",
      "Epoch: 48\n",
      "Training Loss: 1.5135590970389117\t             Training accuracy: 42.35166549682617\n",
      "Validation Loss: 0.7229773960295757\t             Validation accuracy: 75.80999755859375\t             LR:0.005\n",
      "Epoch: 49\n",
      "Training Loss: 1.5092031012720137\t             Training accuracy: 42.43000030517578\n",
      "Validation Loss: 0.7267172057537516\t             Validation accuracy: 75.83000183105469\t             LR:0.005\n",
      "Epoch: 50\n",
      "Training Loss: 1.5102718316161556\t             Training accuracy: 42.413333892822266\n",
      "Validation Loss: 0.7263389003884261\t             Validation accuracy: 75.86000061035156\t             LR:0.005\n",
      "Epoch: 51\n",
      "Training Loss: 1.5062179336034414\t             Training accuracy: 42.676666259765625\n",
      "Validation Loss: 0.7260026806479047\t             Validation accuracy: 75.83999633789062\t             LR:0.005\n",
      "Epoch: 52\n",
      "Training Loss: 1.5137820116746654\t             Training accuracy: 42.22666549682617\n",
      "Validation Loss: 0.7225794765599973\t             Validation accuracy: 75.98999786376953\t             LR:0.005\n",
      "Epoch: 53\n",
      "Training Loss: 1.5102006726935981\t             Training accuracy: 42.349998474121094\n",
      "Validation Loss: 0.7154846216083333\t             Validation accuracy: 75.87000274658203\t             LR:0.005\n",
      "Epoch: 54\n",
      "Training Loss: 1.5036287813552662\t             Training accuracy: 42.651668548583984\n",
      "Validation Loss: 0.7168566058775422\t             Validation accuracy: 75.9800033569336\t             LR:0.005\n",
      "Epoch: 55\n",
      "Training Loss: 1.5067311620026\t             Training accuracy: 42.36000061035156\n",
      "Validation Loss: 0.7106602683568456\t             Validation accuracy: 75.97000122070312\t             LR:0.005\n",
      "Epoch: 56\n",
      "Training Loss: 1.4951586311559941\t             Training accuracy: 42.84166717529297\n",
      "Validation Loss: 0.7132007475871189\t             Validation accuracy: 75.97000122070312\t             LR:0.005\n",
      "Epoch: 57\n",
      "Training Loss: 1.4976888068957623\t             Training accuracy: 42.79999923706055\n",
      "Validation Loss: 0.7086284447247815\t             Validation accuracy: 75.95999908447266\t             LR:0.005\n",
      "Epoch: 58\n",
      "Training Loss: 1.5018754117270268\t             Training accuracy: 42.564998626708984\n",
      "Validation Loss: 0.7097191070295443\t             Validation accuracy: 76.0199966430664\t             LR:0.005\n",
      "Epoch: 59\n",
      "Training Loss: 1.5050195744678156\t             Training accuracy: 42.28499984741211\n",
      "Validation Loss: 0.7182932892802415\t             Validation accuracy: 75.93000030517578\t             LR:0.005\n",
      "Epoch: 60\n",
      "Training Loss: 1.493761893528611\t             Training accuracy: 42.731666564941406\n",
      "Validation Loss: 0.6991817311496492\t             Validation accuracy: 76.19000244140625\t             LR:0.005\n",
      "Epoch: 61\n",
      "Training Loss: 1.4969039748726622\t             Training accuracy: 42.709999084472656\n",
      "Validation Loss: 0.6991258916581512\t             Validation accuracy: 76.19000244140625\t             LR:0.0005\n",
      "Epoch: 62\n",
      "Training Loss: 1.4878140506205528\t             Training accuracy: 43.02333450317383\n",
      "Validation Loss: 0.7000996295813542\t             Validation accuracy: 76.19999694824219\t             LR:0.0005\n",
      "Epoch: 63\n",
      "Training Loss: 1.4963507049881828\t             Training accuracy: 42.62666702270508\n",
      "Validation Loss: 0.6984849441203342\t             Validation accuracy: 76.25\t             LR:0.0005\n",
      "Epoch: 64\n",
      "Training Loss: 1.4957145424539855\t             Training accuracy: 42.65833282470703\n",
      "Validation Loss: 0.6983892999257252\t             Validation accuracy: 76.2699966430664\t             LR:0.0005\n",
      "Epoch: 65\n",
      "Training Loss: 1.4858058582999305\t             Training accuracy: 42.970001220703125\n",
      "Validation Loss: 0.6978963258539795\t             Validation accuracy: 76.25\t             LR:0.0005\n",
      "Epoch: 66\n",
      "Training Loss: 1.4883252480136815\t             Training accuracy: 43.003334045410156\n",
      "Validation Loss: 0.6993826202526214\t             Validation accuracy: 76.27999877929688\t             LR:0.0005\n",
      "Epoch: 67\n",
      "Training Loss: 1.4977998669976111\t             Training accuracy: 42.63833236694336\n",
      "Validation Loss: 0.6974988982176326\t             Validation accuracy: 76.2699966430664\t             LR:0.0005\n",
      "Epoch: 68\n",
      "Training Loss: 1.488730459325095\t             Training accuracy: 42.99833297729492\n",
      "Validation Loss: 0.6968648991767009\t             Validation accuracy: 76.23999786376953\t             LR:0.0005\n",
      "Epoch: 69\n",
      "Training Loss: 1.4988704130593649\t             Training accuracy: 42.54666519165039\n",
      "Validation Loss: 0.6984811172743511\t             Validation accuracy: 76.27999877929688\t             LR:0.0005\n",
      "Epoch: 70\n",
      "Training Loss: 1.494822409488499\t             Training accuracy: 42.81999969482422\n",
      "Validation Loss: 0.7004311559306589\t             Validation accuracy: 76.26000213623047\t             LR:0.0005\n",
      "Epoch: 71\n",
      "Training Loss: 1.497354577789937\t             Training accuracy: 42.62333297729492\n",
      "Validation Loss: 0.6974225803545326\t             Validation accuracy: 76.25\t             LR:0.0005\n",
      "Epoch: 72\n",
      "Training Loss: 1.4952071664302842\t             Training accuracy: 42.61000061035156\n",
      "Validation Loss: 0.6998761125430939\t             Validation accuracy: 76.26000213623047\t             LR:0.0005\n",
      "Epoch: 73\n",
      "Training Loss: 1.4922604406439166\t             Training accuracy: 42.77000045776367\n",
      "Validation Loss: 0.6987259372784074\t             Validation accuracy: 76.2699966430664\t             LR:0.0005\n",
      "Epoch: 74\n",
      "Training Loss: 1.4994653534533373\t             Training accuracy: 42.57833480834961\n",
      "Validation Loss: 0.6975055450846435\t             Validation accuracy: 76.26000213623047\t             LR:0.0005\n",
      "Epoch: 75\n",
      "Training Loss: 1.4915352130749586\t             Training accuracy: 42.79999923706055\n",
      "Validation Loss: 0.6966317673777319\t             Validation accuracy: 76.26000213623047\t             LR:0.0005\n",
      "Epoch: 76\n",
      "Training Loss: 1.4909601315760663\t             Training accuracy: 42.7599983215332\n",
      "Validation Loss: 0.6978187354127313\t             Validation accuracy: 76.26000213623047\t             LR:0.0005\n",
      "Epoch: 77\n",
      "Training Loss: 1.4847539041850613\t             Training accuracy: 43.098331451416016\n",
      "Validation Loss: 0.6993024654828819\t             Validation accuracy: 76.2699966430664\t             LR:0.0005\n",
      "Epoch: 78\n",
      "Training Loss: 1.4923513494829126\t             Training accuracy: 42.66999816894531\n",
      "Validation Loss: 0.6964158476537959\t             Validation accuracy: 76.25\t             LR:0.0005\n",
      "Epoch: 79\n",
      "Training Loss: 1.4919109348295085\t             Training accuracy: 42.76333236694336\n",
      "Validation Loss: 0.6970223177010846\t             Validation accuracy: 76.23999786376953\t             LR:0.0005\n",
      "Epoch: 80\n",
      "Training Loss: 1.4984991447503633\t             Training accuracy: 42.564998626708984\n",
      "Validation Loss: 0.6963374960194727\t             Validation accuracy: 76.27999877929688\t             LR:0.0005\n",
      "Epoch: 81\n",
      "Training Loss: 1.4901358575454906\t             Training accuracy: 42.848331451416016\n",
      "Validation Loss: 0.6962463586193741\t             Validation accuracy: 76.2300033569336\t             LR:0.0005\n",
      "Epoch: 82\n",
      "Training Loss: 1.496719612749909\t             Training accuracy: 42.57666778564453\n",
      "Validation Loss: 0.6957263244185478\t             Validation accuracy: 76.30999755859375\t             LR:0.0005\n",
      "Epoch: 83\n",
      "Training Loss: 1.4915321071519019\t             Training accuracy: 42.75666809082031\n",
      "Validation Loss: 0.6965964216335564\t             Validation accuracy: 76.23999786376953\t             LR:0.0005\n",
      "Epoch: 84\n",
      "Training Loss: 1.4953676284249149\t             Training accuracy: 42.5\n",
      "Validation Loss: 0.6959685480139058\t             Validation accuracy: 76.26000213623047\t             LR:0.0005\n",
      "Epoch: 85\n",
      "Training Loss: 1.4940267642423797\t             Training accuracy: 42.630001068115234\n",
      "Validation Loss: 0.6951677728990081\t             Validation accuracy: 76.33000183105469\t             LR:0.0005\n",
      "Epoch: 86\n",
      "Training Loss: 1.4885183877782273\t             Training accuracy: 42.81666564941406\n",
      "Validation Loss: 0.6964305282398394\t             Validation accuracy: 76.27999877929688\t             LR:0.0005\n",
      "Epoch: 87\n",
      "Training Loss: 1.4879477149896276\t             Training accuracy: 42.814998626708984\n",
      "Validation Loss: 0.6930960623701666\t             Validation accuracy: 76.26000213623047\t             LR:0.0005\n",
      "Epoch: 88\n",
      "Training Loss: 1.4923569848542528\t             Training accuracy: 42.599998474121094\n",
      "Validation Loss: 0.6938403744226808\t             Validation accuracy: 76.2699966430664\t             LR:0.0005\n",
      "Epoch: 89\n",
      "Training Loss: 1.4832814475620733\t             Training accuracy: 42.96500015258789\n",
      "Validation Loss: 0.6938655558665088\t             Validation accuracy: 76.27999877929688\t             LR:0.0005\n",
      "Epoch: 90\n",
      "Training Loss: 1.4893447998235982\t             Training accuracy: 42.7783317565918\n",
      "Validation Loss: 0.6949478594740485\t             Validation accuracy: 76.27999877929688\t             LR:0.0005\n",
      "Epoch: 91\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/dr/704qjz3n21lgqk009dttw33w0000gn/T/ipykernel_83202/2425144064.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[0mcurr_lr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparam_groups\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'lr'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m     \u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m     \u001B[0mtest\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/dr/704qjz3n21lgqk009dttw33w0000gn/T/ipykernel_83202/3355552980.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m()\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[0mtotal\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m     \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mimages\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_loader\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m         \u001B[0mimages\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mimages\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m         \u001B[0mlabels\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    528\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sampler_iter\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    529\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 530\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    531\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    532\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIterable\u001B[0m \u001B[0;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    568\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    569\u001B[0m         \u001B[0mindex\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# may raise StopIteration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 570\u001B[0;31m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_fetcher\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfetch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# may raise StopIteration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    571\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pin_memory\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    572\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_utils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\u001B[0m in \u001B[0;36mfetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     47\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mfetch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     48\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mauto_collation\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 49\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     50\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     51\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     47\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mfetch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     48\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mauto_collation\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 49\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     50\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     51\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/datasets/mnist.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, index)\u001B[0m\n\u001B[1;32m    143\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    144\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransform\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 145\u001B[0;31m             \u001B[0mimg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    146\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    147\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtarget_transform\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/transforms/transforms.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, img)\u001B[0m\n\u001B[1;32m     93\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mimg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     94\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mt\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransforms\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 95\u001B[0;31m             \u001B[0mimg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     96\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mimg\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     97\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/transforms/transforms.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, pic)\u001B[0m\n\u001B[1;32m    133\u001B[0m             \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mConverted\u001B[0m \u001B[0mimage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    134\u001B[0m         \"\"\"\n\u001B[0;32m--> 135\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_tensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpic\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    136\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    137\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__repr__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/transforms/functional.py\u001B[0m in \u001B[0;36mto_tensor\u001B[0;34m(pic)\u001B[0m\n\u001B[1;32m    145\u001B[0m     \u001B[0;31m# handle PIL Image\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    146\u001B[0m     \u001B[0mmode_to_nptype\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m\"I\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mint32\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"I;16\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mint16\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"F\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat32\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 147\u001B[0;31m     \u001B[0mimg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_numpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpic\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode_to_nptype\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpic\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0muint8\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    148\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    149\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mpic\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"1\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/PIL/Image.py\u001B[0m in \u001B[0;36m__array__\u001B[0;34m(self, dtype)\u001B[0m\n\u001B[1;32m    698\u001B[0m             \u001B[0mnew\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"data\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtobytes\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    699\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 700\u001B[0;31m         \u001B[0;32mclass\u001B[0m \u001B[0mArrayData\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    701\u001B[0m             \u001B[0m__array_interface__\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnew\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    702\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch: {epoch+1}')\n",
    "\n",
    "    #get the current learning rate\n",
    "    curr_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    train()\n",
    "    test()\n",
    "\n",
    "    epochs.append(epoch)\n",
    "\n",
    "\n",
    "\n",
    "    #step the learning rate scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('Finished Training')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the 10000 test images: {acc} %')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plotLosses(epochs, Loss, title):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.title(title)\n",
    "    plt.plot(epochs, Loss, label = \"Loss\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.savefig(title + '.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#plot the loss diagrams\n",
    "plotLosses(epochs, train_loss_average, f'FCN-{opt}_train_loss lr:{learning_rate} acc:{acc}')\n",
    "plotLosses(epochs, valid_loss_average, f'FCN-{opt}_valid_loss lr:{learning_rate} acc:{acc}')\n",
    "\n",
    "#plot combo loss diagrams\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title(f'FCN-{opt} lr:{learning_rate} acc:{acc}')\n",
    "plt.plot(epochs, train_loss_average, label = \"Training loss\")\n",
    "plt.plot(epochs, valid_loss_average, label = 'Validation loss')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.savefig(f'FCN-Loss-{opt} lr:{learning_rate} acc:{acc}.png')\n",
    "\n",
    "#plot validation accuracies\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title(f'FCN-{opt} lr:{learning_rate} acc:{acc}')\n",
    "plt.plot(epochs, train_accuracy, label = \"Training accuracy\")\n",
    "plt.plot(epochs, valid_accuracy, label = 'Validation accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.savefig(f'FCN-Accuracy-{opt} lr:{learning_rate} acc:{acc}.png')\n",
    "\n",
    "PATH = f'./FCN-{opt}-lr:{learning_rate}-acc:{acc}.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}